%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Composition as software development}
\label{chap:practicalities}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\eblettrinedbl{T}{hroughout the previous chapters,} I have presented concepts,
techniques, classes and functions for modeling notation and composition in
code, accompanied by numerous visualizations, all executed in the context of an
interactive Python interpreter session. In light of that, it's important to
understand that when composing computationally, I rarely work with the
interactive console. Interactive sessions demonstrate simple techniques well,
and allow for inspection of live code objects, but are prone to typing errors
-- consider the difficulty of typing dozens of lines perfectly -- and
ultimately discourage an iterative workflow.

Iteration is crucial for composing large-scale works, and requires that code
and other assets be preserved throughout each cycle of definition and
visualization so that they can be progressively revised, amended and otherwise
reconfigured. Code must be saved to disk as modules in order to be executed or
imported into other code. Likewise, code should be encapsulated for both
manageability and legibility, preferably organized into multiple files
articulating their structure or purpose. Of course, once code is arranged as
files on disk, a whole variety of additional questions emerge: How should that
code be organized? In how many files? How much and which code in each each
file? Where should the files be kept? Does the code create other assets? Where
are these stored? How are they named? How is the code executed? How is the
project structure maintained? How are changes to the project saved, and how
does one compare one version to another? And how is the code in the project
tested to guarantee that it works at all, let alone creates the musical result
one expects and desires?

The answers to such questions -- and there often are clear answers -- revolve
the practicalities of managing not simply a musical endeavor, but a software
project: code and directory structuring, development tools and workflows,
version control and testing. All of these are discussed, in greater or lesser
detail, in the following sections.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Score directory layout}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

When working computationally, a structured, standardized approach to arranging
one's compositional workspace clarifies both the way one thinks about the act
of composing, as well as the more menial workflows of document preparation
which are inseparable from score-based composition. Standardization also allows
one to reuse tools designed to manage one score package on another. Each of the
\emph{Invisible Cities} scores included in part II of this dissertation are
implemented as Python packages extending both Abjad's model of notation and
Consort's model of composition. Likewise, each \emph{Invisible Cities} score
package is structured into a nearly identical arrangement of eight top-level
directories, each with a clearly delineated purpose and substructure.

\begin{figure}[h!]
\begin{singlespacing}
\vspace{-0.5\baselineskip}
\noindent%
\dirtree{%
.1  ersilia/.
    .2  \_\_init\_\_.py\DTcomment{
        The score package Python initializer.
        }.
    .2  build/\DTcomment{
        LilyPond and LaTeX files for building document targets.
        }.
    .2  distribution/\DTcomment{
        Finished PDFs for performers and conductors.
        }.
    .2  etc/\DTcomment{
        Notes, to-do lists and plans.
        }.
    .2  makers/\DTcomment{
        Customized segment-makers, score templates and other classes.
        }.
    .2  materials/\DTcomment{
        Materials used to configure segment-makers.
        }.
    .2  segments/\DTcomment{
        Configured segment-makers and their illustrations.
        }.
    .2  stylesheets/\DTcomment{
        LilyPond stylesheets.
        }.
    .2  test/\DTcomment{
        The score package test suite.
        }.
}
\end{singlespacing}
\caption{\emph{Ersilia}'s top-level directory layout.}
\label{fig:ersilias-top-level-directory-layout}
\end{figure}

\noindent The top-level directories named in
\autoref{fig:ersilias-top-level-directory-layout} house specific collections
of assets used during composition or document preparation. Note the presence of
an \texttt{\_\_init\_\_.py} file. This signals to Python that this directory
represents an importable Python package. Assuming Python is aware of the
location of the score, it and any further subpackages within it can be
imported:

\begin{comment}
<abjad>
import ersilia
</abjad>
\end{comment}

\begin{abjadbookoutput}
\begin{singlespacing}
\vspace{-0.5\baselineskip}
\begin{minted}{python}
>>> import ersilia
\end{minted}
\end{singlespacing}
\end{abjadbookoutput}

\noindent Any subdirectories of \texttt{ersilia} also containing
\texttt{\_\_init\_\_.py} files can be imported into the namespace of
\texttt{ersilia}, allowing for the structured organization of any code assets
employed by the score. Consider the various kinds of objects discussed in
earlier chapters. Consort very broadly groups the objects used during
composition into \emph{makers}, \emph{materials} and \emph{segments}. Makers
comprise any classes used during composition, such as segment-maker,
pitch-handler or music specifier classes, but not their instances. Materials
comprise instances of classes representing \emph{out-of-time} musical
constructs, such as pitch segments or music specifiers which have not yet been
deployed along the timeline of the score. Segments comprise configured
instances of the score's segment-maker class which maquette together
previously-defined materials \emph{in-time} into a musical chronology. Each of
these three categories of objects has its own directory in the directory
structure outlined here: \texttt{makers/}, \texttt{materials/} and
\texttt{segments/}. Additionally, materials and segments may be illustrable.
Any associated illustration assets for those code objects is necessarily
grouped together with its originating Python modules.

The document preparation process also involves a number of different types
of assets and tasks. Any LilyPond-typeset PDF created during the composition of
a score, such as a material or segment illustration, or even the final score
itself likely requires a corresponding score-specific stylesheet containing
the typographic overrides and LilyPond context definitions pertinent to that
score. These stylesheets reside in the top-level \texttt{stylesheets/}
directory. Scores composed with Abjad and Consort and typeset with LilyPond and
LaTeX involve potentially many source files: LilyPond sources for the musical
content, yet more LilyPond sources for concatenating and styling that content,
LaTeX sources for cover pages, prefaces and performance notes, and still more
LaTeX sources for concatenating the PDFs created while typesetting various
other sources. These source files, in their various stages of typesetting,
occupy the \texttt{build/} directory. Finally, the finished documents, ready to
be delivered to ensembles, occupy the \texttt{distribution/} directory.

\subsection{Makers}
\label{ssec:makers}

Each score's \texttt{makers/} directory houses classes specific to that score,
with each class stored on disk in its own Python module of the same name. In
the case of my three \emph{Invisible Cities} scores, these makers always
comprise subclasses of Consort's \texttt{SegmentMaker} and
\texttt{ScoreTemplate} classes. The segment-maker subclasses effectively
pre-load common information about the score, such as what time signatures to
permit by default or what the end-of-score markup should look like. They may
also define a considerable amount of additional score post-processing, as in
the case of \emph{Armilla}, where many passes of voice copying were required to
create the typography for the bowing staves. A score's score template class
necessarily defines the score's instrumentation and context hierarchy, giving
the order and grouping of each performer's staff. As none of the scores in this
dissertation make use of common instrumentations, each requires that a
completely new score template be defined.

Any other class definitions required by the score package should also be placed
into the \texttt{makers/} directory. For example, \emph{Plague Water}, whose
directory structure is effectively identical to the \emph{Invisible Cities}
series but whose composition model both predated and heavily informed the
development of Consort, houses nearly thirty separate class definitions in its
\texttt{makers/} directory.

\subsection{Material packages}
\label{ssec:material-packages}

Materials represent \emph{out-of-time} musical objects, such as pitch
collections, rhythm-makers, and even fully configured music specifiers, which
may appear at some point in the time-line of a piece. They are implemented as
importable Python packages, grouped flatly into the score package's top-level
\texttt{materials/} directory, itself a Python package due to the presence of
an initializer file. Like the makers modules, material definition module
define only a single object.

\begin{figure}[h!]
\begin{singlespacing}
\vspace{-0.5\baselineskip}
\dirtree{%
.1  materials/.
    .2  \_\_init\_\_.py\DTcomment{
        The subpackage initializer.
        }.
    .2  abbreviations/\DTcomment{
        A material package.
        }.
    .2  dense\_timespan\_maker/\DTcomment{
        Another material package.
        }.
    .2  guitar\_agitato\_music\_specifier/\DTcomment{
        Yet another material package.
        }.
    .2  guitar\_strummed\_music\_specifier/.
    .2  guitar\_tremolo\_music\_specifier/.
    .2  guitar\_undulation\_tremolo\_music\_specifier/.
    .2  percussion\_bamboo\_windchimes\_music\_specifier/.
    .2  percussion\_crotales\_flash\_music\_specifier/.
    .2  percussion\_crotales\_interruption\_music\_specifier/.
    .2  ....
    .2  ...\DTcomment{
        Many more material packages.
        }.
}
\end{singlespacing}
\caption{Overview of \emph{Ersilia}'s \texttt{materials/} directory.}
\end{figure}

Each material package contains at the least its own initializer as well as a
\texttt{definition.py} file consisting of Python code which defines or
configures that material. Crucially, the actual code object expressed in that
definition.py should be named after the material package itself. This
simplifies the Python import process a great deal. Simple importing utilities
can then be written to iterate over every directory within the
\texttt{materials/} directory, producing corresponding Python import commands
of the form \mintinline[breaklines=true]{python}{from my_material.definition
import my_material}. Automatically importing the objects defined in each
material package into the \texttt{materials} namespace allows those objects to
be easily referenced from within each segment definition:

\begin{comment}
<abjad>[text_width=105]
materials_names = dir(ersilia.materials)
materials_names = [x for x in materials_names if not x.startswith('_')]
print(materials_names)
</abjad>
\end{comment}

\begin{abjadbookoutput}
\begin{singlespacing}
\vspace{-0.5\baselineskip}
\begin{minted}{python}
>>> materials_names = dir(ersilia.materials)
>>> materials_names = [x for x in materials_names if not x.startswith('_')]
>>> print(materials_names)
['abbreviations', 'dense_timespan_maker', 'guitar_agitato_music_specifier',
'guitar_continuo_music_specifier', 'guitar_pointillist_harmonics_music_specifier',
'guitar_strummed_music_specifier', 'guitar_tremolo_music_specifier',
'guitar_undulation_tremolo_music_specifier', 'percussion_bamboo_windchimes_music_specifier',
'percussion_crotales_flash_music_specifier', 'percussion_crotales_interruption_music_specifier',
'percussion_low_pedal_music_specifier', 'percussion_marimba_agitato_music_specifier',
'percussion_marimba_ostinato_music_specifier', 'percussion_marimba_tremolo_music_specifier',
'percussion_snare_interruption_music_specifier', 'percussion_temple_block_fanfare_music_specifier',
'percussion_tom_fanfare_music_specifier', 'permitted_time_signatures', 'piano_agitato_music_specifier',
'piano_arm_cluster_music_specifier', 'piano_glissando_music_specifier',
'piano_palm_cluster_music_specifier', 'piano_pedals_music_setting', 'piano_pointillist_music_specifier',
'piano_string_glissando_music_specifier', 'piano_tremolo_music_specifier', 'pitch_pipe_music_specifier',
'saxophone_agitato_music_specifier', 'shaker_decelerando_music_specifier',
'shaker_sporadic_music_specifier', 'shaker_tremolo_music_specifier', 'sparse_timespan_maker',
'string_agitato_music_specifier', 'string_legato_music_specifier', 'string_low_pedal_music_specifier',
'string_ostinato_music_specifier', 'string_overpressure_music_specifier',
'string_pointillist_music_specifier', 'string_tremolo_music_specifier', 'sustained_timespan_maker',
'tutti_timespan_maker', 'wind_agitato_music_specifier', 'wind_continuo_music_specifier',
'wind_low_pedal_music_specifier', 'wind_ostinato_music_specifier', 'wind_pointillist_music_specifier',
'wind_tremolo_music_specifier']
\end{minted}
\end{singlespacing}
\end{abjadbookoutput}

\begin{figure}[h!]
\begin{singlespacing}
\vspace{-0.5\baselineskip}
\dirtree{%
.1  guitar\_tremolo\_music\_specifier/.
    .2  \_\_init\_\_.py\DTcomment{
        The material package's Python initializer.
        }.
    .2  definition.py\DTcomment{
        The material's definition file.
        }.
    .2  illustration.ly\DTcomment{
        The material illustration's LilyPond source.
        }.
    .2  illustration.pdf\DTcomment{
        The material's rendered illustration.
        }.
}
\end{singlespacing}
\caption{Directory listing of \emph{Ersilia}'s
\texttt{guitar\_tremolo\_music\_specifier} material package.}
\end{figure}

Materials -- depending on their type -- may be illustrable, as described in
\autoref{sec:representing-objects}. Any generated illustration assets --
comprising a LilyPond input file and its resulting PDF -- are stored in the
material package alongside their originating definition module. The means by
which these illustration files come to reside there is elaborated on in
\autoref{ssec:illustrating-and-persisting-segments}.

\subsection{Segment packages}
\label{ssec:segment-packages}

Segments, like materials, are implemented as Python packages, grouped together
into the top-level \texttt{segments/} directory. They can be imported, they
each have an initializer, and they each have a definition module containing the
definition of that segment's segment-maker. As Consort's segment-maker class is
illustrable, each segment package eventually houses that segment's illustration
LilyPond sources and output PDFs.

\begin{figure}[h!]
\begin{singlespacing}
\vspace{-0.5\baselineskip}
\dirtree{%
.1  segments/.
    .2  \_\_init\_\_.py\DTcomment{
        The subpackage initializer.
        }.
    .2  \_\_metadata\_\_.py\DTcomment{
        Metadata about the order of segments in the score.
        }.
    .2  chemish/\DTcomment{
        A segment package.
        }.
        .3  \_\_init\_\_.py\DTcomment{
            The segment package's Python initializer.
            }.
        .3  \_\_metadata\_\_.py\DTcomment{
            Auto-generated metadata about this score segment.
            }.
        .3  definition.py\DTcomment{
            The segment's definition file, containing a configured
            segment-maker.
            }.
        .3  illustration.ly\DTcomment{
            The segment illustration's LilyPond source.
            }.
        .3  illustration.pdf\DTcomment{
            The segment's rendered illustration.
            }.
    .2  cut\_1/\DTcomment{
        Another segment package.
        }.
        .3  ....
    .2  komokome/\DTcomment{
        Another segment package.
        }.
        .3  ....
    .2  cut\_2/\DTcomment{
        Another segment package.
        }.
        .3  ....
    .2  sort/\DTcomment{
        Yet another segment package.
        }.
        .3  ....
}
\end{singlespacing}
\caption{Overview of \emph{Ersilia}'s \texttt{segments/} directory.}
\end{figure}

Each segment subpackage may also house a \texttt{\_\_metadata\_\_.py}
module, which stores information about that segment such as the number of
measures it contains, the final time signature and tempo, and so forth. This
information is generated automatically during the segment-maker's
interpretation, and allows other segment-makers in other segment packages to
draw conclusions about their own segment's context in the full score without
requiring the re-interpretation of any other segments. Like the illustration
sources, these are discussed in more depth in
\autoref{ssec:illustrating-and-persisting-segments}.

A \texttt{\_\_metadata\_\_.py} module sibling to each segment package simply
defines the order of segments. For example, the order of segments in
\emph{Ersilia} is \texttt{komokome}, \texttt{cut\_1}, \texttt{sort},
\texttt{cut\_2}, then \texttt{chemish}. Such an order must be declared
explicitly as it cannot be ascertained from the lexical ordering of the names
of the segment packages. The \texttt{segments/}-local metadata module allows
for such an explicit ordering.

\subsection{The \texttt{stylesheets/} directory}
\label{ssec:the-stylesheets-directory}

The \texttt{stylesheets/} directory consists of LilyPond files containing
typographic overrides, context definitions, document header markup, page layout
configuration and Scheme function definitions. The file \texttt{stylesheet.ily}
represents the primary stylesheet for the entire score, and contains most of
the typographic customization. However, LilyPond stylesheets can
\emph{cascade}: multiple stylesheets can be included into the same master score
file with definitions in subsequently included stylesheets overriding those in
the earlier. Likewise, stylesheets -- because they are simply LilyPond files --
can be included directly into one another.

For example, in \emph{Ersilia}, the master stylesheet file
\texttt{stylesheet.ily} directly includes Scheme definitions from the
file \texttt{scheme.ily}. That master stylesheet is included into the
interpreted LilyPond source of every segment. However, segments beyond the
first also include the stylesheet file \texttt{nonfirst-segment.ily} which
suppresses the appearance of titles and other headers at the top of those
segment illustrations.

\begin{figure}[h!]
\begin{singlespacing}
\vspace{-0.5\baselineskip}
\dirtree{%
.1  stylesheets/.
    .2  nonfirst-segment.ily\DTcomment{
        Style information for segments after the first segment.
        }.
    .2  parts-landscape.ily\DTcomment{
        Style information for landscape-orientation parts.
        }.
    .2  parts-portrait.ily\DTcomment{
        Style information for portrait-orientation parts.
        }.
    .2  scheme.ily\DTcomment{
        LilyPond Scheme commands to be included in the primary stylesheet.
        }.
    .2  stylesheet.ily\DTcomment{
        The primary stylesheet.
        }.
}
\end{singlespacing}
\caption{
Directory listing of \emph{Ersilia}'s \texttt{stylesheets/} directory.
}
\end{figure}

Because LilyPond supports the inclusion of one LilyPond source file into
another, it is possible to define the musical contents of a work in one source
file and collect global typographic overrides into another. This is the
approach I have taken, out of necessity, when building scores with Abjad and
Consort. It is certainly possible to define every one of the typographic
overrides found in \texttt{stylesheet.ily} in Abjad via its top-level
\texttt{override()} and \texttt{set\_()} functions. However, typesetting the
illustration source of a segment in LilyPond generally takes less time than for
that segment to be interpreted in Python. By separating out typographic
overwrites from the musical \enquote{content} it becomes easier to iterate over
refining those overrides by simply adjusting the stylesheet by hand and
recompiling the already-interpreted segment illustration sources.

\subsection{The \texttt{build/} directory}
\label{ssec:the-build-directory}

The \texttt{build/} directory holds source files pertinent to building scores
and parts, along within any component documents, including front and back
covers, prefaces or performance notes. The contents of the \texttt{build/}
directory are organized into \emph{document targets} and \emph{sources}. Each
document target subdirectory consists of source files for producing scores and
parts in a particular format, such as tabloid or A4 paper, or for a particular
performance or language translation. Sources consist of any LilyPond and LaTeX
files containing content to be included into document targets, such as segment
illustration LilyPond sources, LilyPond stylesheets or LaTeX includes -- housed
in \texttt{assets/} -- containing blocks of prose to be flowed into a preface.

\begin{figure}[h!]
\begin{singlespacing}
\vspace{-0.5\baselineskip}
\dirtree{%
.1  build/.
    .2  11x17-landscape/\DTcomment{
        A document build target directory.
        }.
        .3  ....
    .2  11x17-portrait/\DTcomment{
        Another document build target directory.
        }.
        .3  ....
    .2  assets/\DTcomment{
        LaTeX files to be included into each preface layout.
        }.
        .3  calvino.tex.
        .3  instrumentation.tex.
        .3  leguin.tex.
        .3  performance-notes.tex.
    .2  legal-landscape/\DTcomment{
        Another document build target directory.
        }.
        .3  ....
    .2  legal-portrait/\DTcomment{
        Yet another document build target directory.
        }.
        .3  ....
    .2  parts.ily\DTcomment{
        A LilyPond include file for generating parts.
        }.
    .2  segments/\DTcomment{
        Segment illustration LilyPond sources.
        }.
        .3  chemish.ily.
        .3  cut-1.ily.
        .3  cut-2.ily.
        .3  komokome.ily.
        .3  sort.ily.
    .2  segments.ily\DTcomment{
        A LilyPond include file giving the order of the segments to
        concatenate.
        }.
}
\end{singlespacing}
\caption{Overview of \emph{Ersilia}'s \texttt{build/} directory.}
\end{figure}

The file \texttt{parts.ily}, discussed in \autoref{ssec:part-extraction},
defines LilyPond commands for outputting parts. The file \texttt{segments.ily}
defines -- in LilyPond syntax -- the order in which the segment illustration
sources, collected in the \texttt{segments/} subdirectory of the
\texttt{build/} directory, are to be concatenated.

\begin{figure}[h!]
\begin{singlespacing}
\vspace{-0.5\baselineskip}
\dirtree{%
.1  11x17-landscape/\DTcomment{
    A build target directory.
    }.
    .2  Makefile\DTcomment{
        A Makefile for GNU \texttt{make} affords various build tasks.
        }.
    .2  back-cover.pdf\DTcomment{
        PDF output of the back cover LaTeX source.
        }.
    .2  back-cover.tex\DTcomment{
        LaTeX source for the back cover.
        }.
    .2  front-cover.pdf\DTcomment{
        PDF output of the front cover LaTeX source.
        }.
    .2  front-cover.tex\DTcomment{
        LaTeX source for the back cover.
        }.
    .2  music.ly\DTcomment{
        LilyPond source for the concatenated score segments.
        }.
    .2  music.pdf\DTcomment{.
        PDF output for the concatenated score segments LilyPond source.
        }.
    .2  parts.ly\DTcomment{
        LilyPond source for generating individual parts PDFs.
        }.
    .2  preface.pdf\DTcomment{
        PDF output for the preface LaTeX source.
        }.
    .2  preface.tex\DTcomment{
        LaTeX source for the preface.
        }.
    .2  score.pdf\DTcomment{
        PDF output of the complete score LaTeX source.
        }.
    .2  score.tex\DTcomment{
        LaTeX source for the complete score.
        }.
}
\end{singlespacing}
\caption{Directory listing of a document build target in \emph{Ersilia}.}
\end{figure}

Each document target directory consists of a similar collection of files: LaTeX
sources for the front cover, back cover, and preface, LilyPond sources for the
musical content of the score itself and parts, and a master LaTeX source which
combines covers, the preface and the music into a single score PDF. The
LilyPond \texttt{music.ily} contains \texttt{\textbackslash{}include}
statements which pull in the \texttt{segments.ily} file from the
\texttt{build/} directory as well as the score's main LilyPond stylesheet from
the top-level \texttt{stylesheets} directory. A Makefile, which defines build
commands for the GNU \texttt{make} command-line utility, can also help automate
various document target tasks, such as recompiling all LaTeX documents in the
correct order to produce a finished score.

\subsection{The \texttt{etc/} and \texttt{distribution/} directories}
\label{ssec:the-etc-and-distribution-directories}

The \texttt{etc/} and \texttt{distribution/} directories are perhaps the
simplest. The former holds any notes, plans or to-do lists pertinent to the
compositional process of the score while the latter collects completed scores
and parts for each document target from the \texttt{build/} directory.

\subsection{The \texttt{test/} directory}
\label{ssec:the-test-directory}

Finally, the \texttt{test/} directory contains Python modules defining
parameterized tests which attempt to import each material package and then
import and illustrate each segment in the entire score. The test modules are
run by the \texttt{pytest} testing tool.

\begin{figure}[h!]
\begin{singlespacing}
\vspace{-0.5\baselineskip}
\dirtree{%
.1  test/.
.2  test\_materials.py\DTcomment{
    Parameterized tests for validating integrity of each material package.
    }.
.2  test\_segments.py\DTcomment{
    Parameterized tests for validating integrity of each segment package.
    }.
}
\end{singlespacing}
\caption{Parameterized tests.}
\end{figure}

Note that these tests do not attempt to guarantee that a particular segment
produces some score exactly matching a target, but simply that the
segment-maker manages to interpret without failure, and that LilyPond manages
to typeset the resulting source without error.

\subsection{Python packaging}
\label{ssec:python-packaging}

Each score package should also be properly \emph{packaged} according to Python
standards so that it can be installed on other systems. This might strike
composers as an unmotivated suggestion. Why should one structure their private
score such that it can be used by others? Making a score installable in this
way affords a number of conveniences related to testing. Installable scores can
be tested in \emph{virtual environments} -- a common Python practice -- by
automated test runners like
\texttt{tox}\footnote{https://pypi.python.org/pypi/tox} or run on remote
continuous-integration testing services such as
Travis-CI.\footnote{https://travis-ci.org/}

\begin{figure}[h!]
\begin{singlespacing}
\vspace{-0.5\baselineskip}
\dirtree{%
.1  ersilia/.
    .2 .git/\DTcomment{
        The Git repository history.
        }.
    .2 .gitignore\DTcomment{
        File patterns to be ignored by the Git version control system.
        }.
    .2 .travis.yml\DTcomment{
        The Travis-CI build configuration script.
        }.
    .2 README.md\DTcomment{
        A MarkDown text file containing introductory information about the
        score package.
        }.
    .2 ersilia/\DTcomment{
        The score package itself.
        }.
    .2 requirements.txt\DTcomment{
        Dependency information, for use when installing on Travis-CI.
        }.
    .2 setup.cfg\DTcomment{
        Python packaging configuration.
        }.
    .2 setup.py\DTcomment{
        The Python package installation script.
        }.
    .2 tox.ini\DTcomment{
        Configuration for the \texttt{tox} automated testing tool.
        }.
}
\end{singlespacing}
\caption{Overview of \emph{Ersilia}'s Python packaging assets.}
\end{figure}

For those who wish to make both their scores and code completely public -- as I
have -- installation affordances are simply necessary for letting others
explore the code as quickly and easily as possible.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Document preparation in detail}
\label{sec:document-preparation-in-detail}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

As with working with Abjad in the simplest case, the work flow of composing and
preparing scores with Consort continues to revolve around a cycle of defining
musical structures in text, illustrating that music visually, then refining the
textual definitions. Unlike creating simple musical examples at the
command-line, as demonstrated throughout this dissertation -- especially in
\autoref{chap:a-model-of-notation} --, managing a large-scale score requires
considerably more tools and many more file-system assets. The following
sections discuss some of the additional complexities involved in organizing and
typesetting a large-scale score computationally.

\subsection{Build tools}
\label{ssec:build-tools}

I make use of a variety of custom build tools for managing assets within a
score package which will not be discussed here in any detail as they are still
rather provisional. These tools simplify various tasks such as creating new
segment and material packages, executing segment definition modules in order to
illustrate the contained segment-makers, comparing new illustration LilyPond
sources and PDF outputs against previously rendered ones, and collecting and
massaging segment LilyPond sources from each segment package into the build
directory for document preparation. Simply put, build tools for score packages
streamline the problems of moving files and folders into their appropriate
locations, executing Python modules, persisting code objects to disk and
cleaning up after any transient files.

\subsection{Illustrating \& persisting segments}
\label{ssec:illustrating-and-persisting-segments}

All of the examples of object illustration demonstrated throughout this
dissertation involve illustrating objects in a live Python interpreter session.
However, in order to construct a score made of potentially many concatenated
segment illustrations, those illustrations must be persisted to disk. While
persistence can certainly also be handled in a live interpreter session,
by-hand illustration and persistence are both error-prone and tedious. One way
to simplify the task of illustrating segments and persisting their
illustrations to disk is by adding executable code to the end of each segment
definition module. When run by Python as a script, those segment definition
modules can be instructed to illustrate  their segment makers and persist the
resulting illustration and segment metadata to disk in the same directory as
the segment definition module. Consider the following trivial segment
definition file, complete with an executable suite at its end:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\begin{minted}{python}
import os
import consort
from abjad import persist


segment_maker = consort.SegmentMaker(
    desired_duration_in_seconds=4,
    )


if __name__ == '__main__':
    illustration, metadata = segment_maker()
    directory_path = os.path.dirname(os.path.abspath(__file__))
    illustration_pdf_file_path = os.path.join(directory_path, 'illustration.pdf')
    metadata_file_path = os.path.join(directory_path, '__metadata__.py')
    persist(illustration).as_pdf(
        pdf_file_path=illustration_pdf_file_path,
        candidacy=True,
        )
    persist(metadata).as_module(
        module_file_path=metadata_file_path,
        object_name='metadata',
        )
\end{minted}
\end{singlespacing}

\noindent When run by Python as a script -- via a command like
\mintinline{bash}{python my_segment_definition.py} -- rather than imported, the
code in the segment definition module executes in the module namespace
\texttt{\_\_main\_\_}. The conditional \mintinline{python}{if __name__ ==
'__main__':} guarantees then that the suite beneath that conditional executes
if and only if the current module name is \texttt{\_\_main\_\_}, again because
the segment definition module was run as a script. This crucially prevents
illustration code from running when the definition module is simply imported
rather than executed. However, if the suite underneath the conditional
\emph{does} execute, it first calls the previously defined segment-maker. That
segment-maker then returns both the illustration and a segment metadata
dictionary. Next, file paths relative to the segment module's file path are
determined in order to persist the just-created illustration and metadata. The
global variable \texttt{\_\_file\_\_} in any Python code module gives the
location of that module on the file system, from which that module's directory
can be determined. Finally, calls to Abjad's top-level \texttt{persist()}
function against the illustration and metadata expose persistence agent
instances which afford persisting each object to disk as a
LilyPond file and Python module respectively. The \texttt{candidacy=True}
keyword argument to \mintinline{python}{persist{illustration}.as_pdf(...)}
checks whether a PDF already exists and only overwrites if the new would
differ.

As mentioned in \autoref{ssec:build-tools}, I make use of custom build tools
for my scores which afford a more elaborate version of the illustration and
persistence task outlined above. One such elaboration passes the metadata for
the previous segment -- if such metadata exists -- to the current
segment-maker's \texttt{\_\_call\_\_()} method. Recall that the previous
segment can be determined by consulting the \texttt{\_\_metadata\_\_.py} module
sibling to the segment packages, as outlined in
\autoref{ssec:segment-packages}. A modified version of the current
segment-maker's metadata is also passed as an argument at call-time, and
includes both a count of the total number of segments and the current segment's
index within those segments. Such metadata allows a segment-maker to
automatically determine if it is the first or last of all segments, as well as
to take into account any pertinent settings effective at the end of the
previous segment, such as the previous segment's ending tempo or time
signature.

Note too that persisting material illustrations can be handled in a nearly
identical fashion. And unlike segments, they do not need to even optionally
consult or persist metadata.

\subsection{Collecting and concatenating segment illustrations}
\label{ssec:collecting-and-concatenating-segment-illustrations}

The model of composition afforded by Consort assumes scores consist of multiple
segments, each of which is persisted as a LilyPond score context based on an
identical score template. This assumption relies on LilyPond's ability to
concatenate like-named contexts. Consider the following LilyPond expression:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\begin{minted}{tex}
{
    \context Score = "The Score" <<
        \context Staff = "Staff A" { c'1 d'1 }
        \context Staff = "Staff B" { c'1 b1 }
    >>
    \context Score = "The Score" <<
        \context Staff = "Staff A" { e'1 f'1 }
        \context Staff = "Staff B" { a1 g1 }
    >>
    \context Score = "The Score" <<
        \context Staff = "Staff A" { g'1 a'1 }
        \context Staff = "Staff B" { f1 e1 }
    >>
}
\end{minted}
\end{singlespacing}

\noindent The above example contains three like-named scores grouped by braces
into a single music expression. Because the scores have identical names and the
staff contexts within them are also identically named, LilyPond concatenates
each like-named context in each score together. The resulting music expression
is equivalent to the following:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\begin{minted}{tex}
\context Score = "The Score" <<
    \context Staff = "Staff A" { c'1 d'1 e'1 f'1 g'1 a'1 }
    \context Staff = "Staff B" { c'1 b1 a1 g1 f1 e1 }
>>
\end{minted}
\end{singlespacing}

\noindent An identical context concatenation process is used to fuse the scores
defined in each segment's illustration file into a single music expression.
First however, those segment illustrations must be collected into the
\texttt{segments/} directory within the \texttt{build/} directory and their
sources massaged to permit concatenation.

Each segment illustration, as it exists in its segment package, represents a
complete, fully-typesettable LilyPond file, consisting of a LilyPond version
statement, pitch-name language command, various stylesheet include commands,
and that segment's score's context block wrapped within a
\texttt{\textbackslash{}score} block:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\begin{minted}{tex}
\version "2.19.17"
\language "english"

#(ly:set-option 'relative-includes #t)

\include "../../stylesheets/stylesheet.ily"

\score {
    \context Score = "The Score" <<
        ...
    >>
}
\end{minted}
\end{singlespacing}

\noindent Such an input cannot simply be included along with the other segment
illustration files to create a concatenated score. In fact, a construction like
the following, with \texttt{\textbackslash{}score} blocks nested within other
\texttt{\textbackslash{}score} blocks, is considered a syntax error by
LilyPond:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\begin{minted}{tex}
\version "2.19.17"

\score {
    {
        \version "2.19.17"
        \score {
            \context Score = "The Score" << c'1 >>
        }
        \version "2.19.17"
        \score {
            \context Score = "The Score" << c'1 >>
        }
        \version "2.19.17"
        \score {
            \context Score = "The Score" << c'1 >>
        }
    }
}
\end{minted}
\end{singlespacing}

\noindent Instead, some simple string processing must be applied against the
illustration file to trim out all content besides the inner score
\texttt{\textbackslash{}context} block, resulting in a much thinner but
includable construction.

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\begin{minted}{tex}
\context Score = "The Score" <<
    ...
>>
\end{minted}
\end{singlespacing}

\noindent This trimming removes unnecessary header and styling information from
each collected segment illustration and allows LilyPond to concatenate the
score contexts together into a single score structure.

Segment collection then involves copying each segment illustration LilyPond
source from its segment package into the \texttt{segments/} subdirectory of the
score package's \texttt{build/} directory, naming that copied illustration
source after its originating segment package, and finally trimming that source
as shown above. As with segment illustration automation, I make use of some
provisional build tools which simplify this process. However, a naive approach
to the task of collecting and trimming segment illustration could also be
implemented in a few dozen lines of Python code. With the segment illustrations
collected into the \texttt{build/} directory, the \texttt{build/} directory's
\texttt{segments.ily} LilyPond include file can be updated based on the segment
order encoded in the \texttt{segments/} directory's
\texttt{\_\_metadata\_\_.py} module. For example, \emph{Ersilia}'s
\texttt{segments.ily} include file ultimately looks like this:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\inputminted{tex}{../../Documents/Scores/ersilia/ersilia/build/segments.ily}
\end{singlespacing}

\noindent Finally, the updated \texttt{segments.ily} file can be included
directly into a document target's \texttt{music.ly} LilyPond source file, to
create the complete musical contents in the appropriate layout for that
document target's paper output format. The LilyPond source for a document
target's musical content might then simply look like the following:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\begin{minted}{tex}
\version "2.19.17"
\language "english"

#(ly:set-option 'relative-includes #t)
\include "../../stylesheets/stylesheet.ily"
#(set-default-paper-size "legal" 'portrait)
#(set-global-staff-size 11)

\score {
    \include "../segments.ily"
}
\end{minted}
\end{singlespacing}

\subsection{Organizing and typesetting LaTeX assets}
\label{ssec:organizing-and-typesetting-latex-assets}

In the spirit of LilyPond's automated musical typesetting, I have chosen to
rely on LilyPond's spiritual predecessor, LaTeX, for handling all
purely-textual or otherwise utilitarian typesetting in the documents I produce.
LaTeX, like LilyPond, takes a textual source file as input, consisting of a
variety of commands which describe the structure and content of a document, and
produces a typeset target, generally as a PDF. Each document target of course
requires more content than simply the musical meat of the score. Title pages,
covers, prefaces and performance notes also require typesetting and should be
handled as simply as possible while maintaining identical content, output
formats, fonts and spacing.

The most complex LaTeX task in my document preparation process involves
formatting identical textual content for different paper sizes and
orientations, as with each document target's preface information. A preface
containing multiple sections, each potentially containing nested lists of
instruments or diagrams, may not format equally well on different paper sizes
and orientations. For example, the preface to \emph{Armilla} contains six
different sections of widely divergent lengths, but fits well in portrait
orientations of tabloid and legal paper when split into two columns. However,
when formatted on letter paper, or in landscape orientation, sections of prose
no longer work in the two column layout cleanly and need to be individually
resized or flowed into more than two columns. Formatting such a preface
properly in both landscape and portrait orientations, in tabloid, letter and
legal paper sizes requires non-trivial rearrangement and must be adjusted by
hand. However, care must be taken not to duplicate content across different
LaTeX source files. Duplicated prose inevitably goes out of sync, creating a
tremendous cognitive burden on the composer as they prepare their documents.

This problem -- needing to provide manually-tweaked alternate layouts for prose
while discouraging by-hand copying -- can be solved by separating out each
section of text in the preface into separate includable LaTeX files, stored in
the \texttt{assets/} subdirectory of the \texttt{build/} directory, and then
including those files back into each alternative preface layout file. Such a
workflow enacts the age-old adage counsel to separate content from layout.

Consider the preface to \emph{Ersilia}, which contains four separate sections:
two quotes, from Italo Calvino and Ursula K. Le Guin, and two passages on
instrumentation and performance. Each of these sections is stored as a separate
LaTeX file in the \texttt{assets/} subdirectory of \emph{Ersilia}'s
\texttt{build/} directory. When preparing prefaces for the tabloid landscape
edition and the legal portrait edition, each collection of prose assets is
flowed into different text grids via the \texttt{textpos} LaTeX package. For
example, the tabloid landscape uses four separate columns, each of varying
widths:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\inputminted[
    firstline=18,
]{tex}{../../Documents/Scores/ersilia/ersilia/build/11x17-landscape/ersilia-11x17-landscape-preface.tex}
\end{singlespacing}

\noindent The legal portrait version uses two columns, with the quotes on the
left side and the performance instructions on the right:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\inputminted[
    firstline=18,
]{tex}{../../Documents/Scores/ersilia/ersilia/build/legal-portrait/ersilia-legal-portrait-preface.tex}
\end{singlespacing}

\noindent In both cases, none of the actual content of the prose appears in the
LaTeX files defining the layout of the prose. This guarantees that any edits or
corrections to the prose will be reflected equally in all layouts of the
preface.

LaTeX can also be used to join documents together. Each document target
contains a master \texttt{score.tex} which combines all other PDF components of
the score together into a single PDF via LaTeX, obviating the need to use any
other PDF-merging tool. For example, the 11x17 portrait \texttt{score.tex} for
\emph{Ersilia} looks like this:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\inputminted{tex}{../../Documents/Scores/ersilia/ersilia/build/11x17-portrait/ersilia-11x17-portrait-score.tex}
\end{singlespacing}

\subsection{Part extraction}
\label{ssec:part-extraction}

When working with LilyPond and Abjad, part extraction relies on two fairly
simple LilyPond mechanisms: \emph{tags} and \emph{book blocks}. In LilyPond,
any music expression can be labeled with a tag, a string or symbol which
identifies that music expression. Later, music expressions can be filtered to
either remove or solely preserve any expression with a given tag. Consider the
following pseudo-score, consisting of a score containing three staves and a
time signature context:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\begin{minted}{tex}
\keepWithTag #'(time B)
\new Score <<
    \tag #'time \new TimeSignatureContext = "Time Signature Context" { ... }
    \tag #'A \new Staff = "Staff A" { ... }
    \tag #'B \new Staff = "Staff B" { ... }
    \tag #'C \new Staff = "Staff C" { ... }
>>
\end{minted}
\end{singlespacing}

\noindent Each context contained by the \texttt{Score} context -- the three
staves and the time signature context -- is tagged via a LilyPond
\texttt{\textbackslash{}tag} command, associating that context's music
expression with the tag's symbol. The command preceding the score itself --
\texttt{\textbackslash{}keepWithTag \#\'(time B)} -- indicates that the score
should filter out any tagged music expression which do not belong to the list
of expressions \texttt{\#\'(time B)}. That is, the score should omit the two
staves tagged \texttt{A} and \texttt{C}, effectively producing a score
structured like so:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\begin{minted}{tex}
\new Score <<
    \new TimeSignatureContext = "Time Signature Context" { ... }
    \new Staff = "Staff B" { ... }
>>
\end{minted}
\end{singlespacing}

\noindent This tagging technique is used in every score developed with Consort.
Each score's score template includes tag commands labeling both the time
signature context -- which must appear both in the full score and all parts as
it contains time signature, tempo and rehearsal mark information -- as well as
all inner contexts necessary for individual performers. By constructing the
appropriate \texttt{\textbackslash{}keepWithTag} commands, music expressions
representing each performer's part can be constructed easily.
Note the use of \texttt{\textbackslash{}tag} commands throughout the structure
of \emph{Armilla}'s score:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\inputminted[
    gobble=8,
    firstline=19,
    lastline=71,
]{tex}{../../Documents/Scores/armilla/armilla/makers/ArmillaScoreTemplate.py}
\end{singlespacing}

\noindent The time signature context receives its own tag, and the staff groups
wrapping each performer's bowing and fingering staves are also tagged
appropriately.

While tagging allows for extracting parts as music expressions, it does not yet
result in actual documents for each part. LilyPond's book block structure,
combined with the \texttt{\textbackslash{}bookOutputSuffix} command, provide a
concise mechanism for generating multiple output PDFs from a single LilyPond
input file. As demonstrated throughout this document, LilyPond files are
structured into blocks -- context blocks, score blocks, header and paper
blocks, and so forth. The highest level block is a
\texttt{\textbackslash{}book} block. Somewhat like parts in LaTeX, book blocks
separate content from one another by page breaks. Score blocks contained in
separate book blocks are guaranteed to never appear on the same page together.
Furthermore, by specifying a book output suffix within each book block,
LilyPond will not simply separate that book blocks's content by page breaks but
will actually output a wholly separate PDF, whose filename is suffixed with
that book output suffix.

Consider this excerpt from \emph{Ersilia}'s \texttt{parts.ily} file:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\inputminted[
    lastline=23,
]{tex}{../../Documents/Scores/ersilia/ersilia/build/parts.ily}
\end{singlespacing}

\noindent This file contains one book block per instrument. Each book block
specifies an output suffix pertinent to a specific performer in the ensemble.
Each book block also contains a score block whose contents consist entirely of
an include statement -- pointing at \texttt{segments.ily}, which concatenates
all score segments into a single music expression -- wrapped in a
\texttt{\textbackslash{}keepWithTag} command which filters out everything
except that performer's musical content and the global time signature context.

With these techniques in mind, a complete parts-extraction file would
look like the following, from \emph{Ersilia}:

\begin{singlespacing}
\vspace{-0.5\baselineskip}
\inputminted[
    firstline=3,
]{tex}{../../Documents/Scores/ersilia/ersilia/build/11x17-landscape/ersilia-11x17-landscape-parts.ly}
\end{singlespacing}

\noindent Beyond the initial LilyPond boilerplate of specifying a LilyPond
version and pitch-name input language, basically consists of an include for the
global stylesheet, a page-layout command, an include for a stylesheet for
landscape parts and finally an include for the global parts definition file,
\texttt{parts.ily}. When interpreted by LilyPond, the above will generate one
11x17 landscape PDF per book block defined in \texttt{parts.ily}.

Note that there are methods by which composers can generate parts in
LilyPond. Most LilyPond users who work strictly with LilyPond, writing
\enquote{by hand}, would likely places each of the instrumental parts in the
score into a separate file or variable. Those parts would then be combined into
either the full score or a part for a single player as necessary. Because
Consort produces a single score, complete with all parts joined into a single
expression, filtering must be used to \enquote{strip} the score down to the
desired musical elements.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Project maintenance}
\label{sec:project-maintenance}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Because composing in code is essentially software development, and score
undertaken in this fashion benefits not only from the techniques laid out
earlier in this chapter, but also from those practiced daily by developers
working in disciplines beyond music. Such techniques include version control
and testing, both means of managing the stability and complexity of projects
are they grow and change.

\subsection{Automated regression testing}
\label{ssec:testing}

\todo[inline]{\textbf{TODO:} Find citations for testing.}

Regression testing\cite{beazley2013python} examines the stability and
correctness of a software system during the course of development, allowing the
software's authors to verify that changes and revisions to that system have not
introduced errors or unexpected behavior. Rather than testing the system
manually, software authors typically write \emph{automated regression testing
batteries}: collections of tests implemented as functions or classes which can
be run automatically by a testing tool -- a \emph{test runner} --, returning
the results to the authors as a report. Testing philosophies and practices in
the open source community are now very diverse and sophisticated, therefore a
full discussion of software testing is beyond the scope of this document.
Nevertheless, I believe that testing is crucial to the development of any
software system and therefore to any score or composition model implemented in
code.

Both Consort and the various scores implemented with it make extensive use of
tests. These tests take a variety of forms: \emph{documentation tests},
\emph{unit tests}, \emph{system tests} and \emph{parameterized tests}.
Documentation testing, or \enquote{doctesting} in Python parlance, verifies
that the code examples in the documentation strings accompanying classes,
methods and functions are correct. Unit testing examines small fragments of
code, such as individual functions, class initializers or methods, passing in a
variety of input and examining the output for correctness. System testing
verifies that an entire software system functions as expected. In the context
of Consort, auditing the illustration produced by a fully configured
segment-maker would constitute a system test as such an operation touches upon
nearly every class defined in Consort's library. Additionally, parameterized
tests provide a means of applying a single test against a variety of input.
This is used extensively in Abjad and Consort to guarantee that every class in
each system can be instantiated, is fully documented, can be represented as a
string, can be hashed and so forth. Rather than write over 900 hundred separate
tests -- one for each class in Abjad -- all classes can be collected in a list
and passed to a single parameterized test function, which then runs itself
against each class as though that were separate test.

The three scores I implemented with Consort each contain two parameterized
tests in their top-level \texttt{test/} directory. One test verifies that the
objects defined in each material definitions are valid and contain no errors.
The second parameterized test illustrates each segment definition, failing not
only if the segment-maker is unable to interpret itself but also if LilyPond
fails to typeset the resulting illustration source. These per-score tests serve
a number of functions. They allow me to ascertain that the logic implemented in
the score itself, in Consort, in Abjad and in any dependency of these projects
continues to interoperate -- at least non-catastrophically. They also allow me
verify that the LilyPond output produced by the score's segment-makers -- along
with any stylesheet information defined in the score package -- is still valid
LilyPond source code, and has not been deprecated by newer versions of
LilyPond.

All of these types of testing combined act as a kind bulwark against
backsliding both during the development of a project, in the moment, and
afterward when maintaining the longevity of prior work against obsolescence.

%So, why test? It prevents you from losing ground as you work, and acts as a
%bulwark against the obsolescence of the code you write by allowing you to
%verify that it continues to function as expected although the code it depends
%on and the tools it uses for typesetting may change.

%Abjad, Consort and the scores implemented with Consort also make use of
%continuous integration testing services -- specifically with Travis-CI,
%although other services can certainly be used.
%
%Continuous integration testing via Travis-CI or similar service.
%Run your tests on a remote server in a virtual machine.
%This guarantees that
%
%While continuous integration is perhaps overkill when only a single person is
%working on a score, the act of packaging and deploying the score on a remote,
%clean virtual machine still has benefits.
%
%your score can be installed on a fresh machine which is also probably of a
%different architecture.
%
%Also guarantees that any other project your score depends on, e.g. Abjad or any
%of Abjad's dependencies, can also be installed and used in a fresh environment.
%
%Why do things in a fresh environment? Our local workspace can become a
%blind-spot to us.
%
%Tox can also help with this. Gradually though, Python 3 is becoming the
%dominant version of Python, and will eventually obviate the need to perform
%multi-version testing.
%
%So, why test? It prevents you from losing ground as you work, and acts as a
%bulwark against the obsolescence of the code you write by allowing you to
%verify that it continues to function as expected although the code it depends
%on and the tools it uses for typesetting may change.

\subsection{Version control}
\label{ssec:version-control}

\todo[inline]{\textbf{TODO:} Find citations for version control.}

Version control systems\cite{loeliger2009git} -- or \emph{VCS} -- record
changes to sets of files, tracking additions, deletions, name changes and
content modifications, generally on a line-by-line basis. Changes are grouped
together into bundles called \emph{commits}, labeled with a timestamp and
\emph{commit message} elaborating on the purpose or contents of the changes.
The graph of commits made against a project as recorded by the project's VCS,
where each commit is connected to some previous parent commit, constitute the
\emph{history} of that project. While anecdotally uncommon amongst composers,
virtually all software developers make use of version control to greater or
lesser degrees, for a wide variety of reasons.

Version control provides the most compact and legible way of archiving multiple
versions of a project. When making changes, instead of duplicating the
directory containing one's work, giving the copied directory a name like
\enquote{MyProject-year-month-day} or \enquote{MyProject-version-3} and then
editing the contents of that copy, one simply works in the same directory as
always, committing each change to the version control system's history. At any
point and for any reason, any previously committed version of the project can
be recalled. Reverting to an earlier version of the project does not destroy
later changes. Those too, because they have also been recorded in the project's
history, can also be recalled. Most version control systems store their history
in hidden files or directories within the project. For example, every project I
work uses the VCS \texttt{git}\footnote{http://git-scm.com/}, originally
authored by Linus Torvalds, the chief architect of the Linux kernel. Git stores
its history in a hidden directory named \texttt{.git} in the root of the
versioned project, as indicated in \autoref{ssec:python-packaging}.

Many version control systems support \emph{tagging}, the labeling of a commit
in the version history as particularly important. Software projects often tag
commits intended for release to the public with version numbers like
\texttt{1.0}, \texttt{2.5} or even \texttt{v1.8.5-rc3}. Likewise, important
commits in the history of a score's development might be tagged similarly. For
example, the version of the project when the score was first sent to an
ensemble might be tagged \texttt{world-premier}. Tagging allows the composer to
continue revising the score while still always being able to refer back to
milestones in the score's history.

Version control systems make it easier to understand how and why a project was
changed. Not only does each commit have a commit message, allowing the author
to provide some explanation of their actions, but any two commits can be
compared against one another as a \enquote{\emph{diff}}, a description of the
line-by-line differences between each differing file. Reading the diff between
two commits is often more illuminating than reading the descriptions and
intentions in the commits' commit messages. Diffs provide a clear
description of how textual content in a project has changed, making them
especially useful when working in code or when composing textual input to
automated typesetting programs like LilyPond and LaTeX. Consider how difficult
such a version comparison task would be when comparing the contents of two
project directories by hand -- probably impossible, but certainly very
time-consuming and error-prone.

Finally, version control affords collaboration and experimentation.
Collaboration here crucially also includes collaboration with oneself. Many
version control systems, including \texttt{git}, support \emph{branches} which
allow the revision history of the project to split into parallel time-lines
rather than follow a single linear path. One can create branches whenever one
desires, for example when attempting to solve a problem in more than one way
where each attempt is isolated from one another but still maintained by the
project's version history. Branches can also be merged into one another,
converging parallel version histories to back into a linear history. Such
flexibility gives authors the freedom to embark on radical or incremental
revisions and reorganizations of their projects without fear of confusion or
lost work.

\todo[inline]{\textbf{TODO:} Does this require a conclusion?}